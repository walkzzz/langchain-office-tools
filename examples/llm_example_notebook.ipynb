{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Office Tools - LLM 使用示例\n",
    "\n",
    "本Notebook展示了如何使用LangChain Office Tools中的LLMManager来与不同的大语言模型进行交互。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 添加项目根目录到Python路径\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
    "\n",
    "from src.core.llm import LLMManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化LLM管理器\n",
    "llm = LLMManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看当前配置\n",
    "print(f\"当前提供商: {llm.provider}\")\n",
    "print(f\"当前模型: {llm.model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看所有支持的提供商\n",
    "providers = llm.get_available_providers()\n",
    "print(\"支持的提供商:\")\n",
    "for provider in providers:\n",
    "    print(f\"  - {provider}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看OpenAI支持的模型\n",
    "openai_models = llm.get_available_models(\"openai\")\n",
    "print(\"OpenAI支持的模型:\")\n",
    "for model in openai_models:\n",
    "    print(f\"  - {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切换到OpenAI的gpt-4o-mini模型\n",
    "llm.update_provider(\"openai\")\n",
    "llm.update_model(\"gpt-4o-mini\")\n",
    "\n",
    "print(f\"已切换到提供商: {llm.provider}\")\n",
    "print(f\"已切换到模型: {llm.model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备聊天消息\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"你是一个 helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"你好，介绍一下Python编程语言\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用模型（需要配置API密钥）\n",
    "try:\n",
    "    response = llm.chat_completion(messages)\n",
    "    print(\"模型回复:\")\n",
    "    print(response.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"调用模型时出错: {e}\")\n",
    "    print(\"请确保已正确配置API密钥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切换到通义千问模型\n",
    "llm.update_provider(\"qwen\")\n",
    "llm.update_model(\"qwen-turbo\")\n",
    "\n",
    "print(f\"已切换到提供商: {llm.provider}\")\n",
    "print(f\"已切换到模型: {llm.model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用通义千问模型\n",
    "try:\n",
    "    response = llm.chat_completion(messages)\n",
    "    print(\"模型回复:\")\n",
    "    print(response.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"调用模型时出错: {e}\")\n",
    "    print(\"请确保已正确配置API密钥\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}